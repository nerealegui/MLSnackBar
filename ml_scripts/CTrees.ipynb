{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\")) # Increase cell width\n",
    "display(HTML(\"<style>.rendered_html { font-size: 16px; }</style>\")) # Increase font size\n",
    "\n",
    "# Larger figures\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve, f1_score, accuracy_score, precision_recall_curve, confusion_matrix, classification_report\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice #1\n",
    "\n",
    "Classification trees with Titanic data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable description:\n",
    "\n",
    "- **survived:\tSurvival (target variable) - 0 = No, 1 = Yes**\n",
    "- pclass:\tTicket class - 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- sex:\t    Sex\n",
    "- age:\t    Age in years\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic\n",
    "- parch:\t# of parents / children aboard the Titanic\n",
    "- ticket:\tTicket number\n",
    "- fare:\t    Passenger fare\n",
    "- cabin:\tCabin number\n",
    "- embarked:\tPort of Embarkation - C = Cherbourg, Q = Queenstown, S = Southampton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset and review null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "\n",
    "# Red data\n",
    "filename = 'titanic.xlsx'\n",
    "df = pd.read_excel(filename, 1) #it has two sheets, we load the 2nd one\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Records and variables: \", df.shape)\n",
    "print (\"Column names: \", df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 variables with null values, mostly cabin and age. <BR>\n",
    "We can discard cabin since it appears to be meaningless (and also ticket). <BR> \n",
    "We will need to delete records with missing values, otherwise the model will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['cabin'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppping cabin and ticket\n",
    "df.drop(labels=['cabin', 'ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show % of records from each of the survived class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def class_perc(data):\n",
    "    lendata = len(data)\n",
    "    classes = Counter(data)\n",
    "    \n",
    "    for sclass, freq in classes.items():\n",
    "        perc = (freq / lendata) * 100\n",
    "        print(f\"Class '{sclass}': {perc:.2f}%\")\n",
    "\n",
    "class_perc(df['survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['embarked', 'age', 'fare'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to split it into training and test (with same class distribution of survived variable in each set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_df(dataframe, seed=None, percentage=0.8):\n",
    "    \n",
    "    X = df.loc[:, dataframe.columns != 'survived']\n",
    "    y = df['survived']\n",
    "\n",
    "    return train_test_split(X, y, test_size=1-percentage, random_state=seed, stratify=y) # note the stratify parameter\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_df(df, seed=42, percentage=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data set: \", X_train.shape)\n",
    "print(\"Testing data set: \", X_test.shape)\n",
    "class_perc(Y_train.to_frame(name='survived')[\"survived\"])\n",
    "class_perc(Y_test.to_frame(name='survived')[\"survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "titanic_tree = DecisionTreeClassifier(random_state=42)\n",
    "titanic_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look to the performance of the classifier (by using initially Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = titanic_tree.predict(X_test)\n",
    "print(\"Accuracy = {0:.4f}\".format(accuracy_score(Y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take a look to the tree itself. This is a bit complex since sklearn does not provide a way to visualize the models. To that end, we will need to make use of an external library: `pydotplus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pydotplus\n",
    "\n",
    "# ! pip install graphviz \n",
    "# you may need to install this library directly from https://graphviz.gitlab.io/_pages/Download/Download_windows.html \n",
    "# and then uncomment following two lines\n",
    "#import os\n",
    "#os.environ[\"PATH\"] += os.pathsep + 'C:\\Program Files (x86)\\Graphviz2.38/bin/'(installation folder)\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_tree(tree, feature_names):\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(tree, out_file=dot_data, feature_names=feature_names,\n",
    "                    filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(titanic_tree, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nodes and leaves?\n",
    "print(\"Number of nodes: \", titanic_tree.tree_.node_count)\n",
    "print(\"Number of leaves: \", titanic_tree.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(X_train.columns, titanic_tree.feature_importances_) #average reduction in impurity resulting from splitting at each node of the tree using that feature\n",
    "plt.title('Feature Importance', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will prune the tree to see if we can improve performance.\n",
    "\n",
    "There are different Pruning Parameters:\n",
    "\n",
    " - max_leaf_nodes: Reduce the number of leaf nodes\n",
    " - min_samples_leaf: Restrict the size of sample leaf. Minimum sample size in terminal nodes can be fixed to 30, 100, 300 or 5% of total \n",
    " - max_depth: Reduce the depth of the tree to build a generalized tree. Set the depth of the tree to 3, 5, 10 depending after verification on test data\n",
    " - etc..\n",
    "\n",
    "Let's focus on the depth of the tree. We will test different depth thresholds via CV by using the `GridSearchCV` provided by sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': range(1,16)} # 15 different depth levels\n",
    "\n",
    "titanic_tree_pruned_cv = GridSearchCV(titanic_tree, \n",
    "                   param_grid,\n",
    "                   scoring='accuracy',\n",
    "                   cv=5 , n_jobs=1, verbose=1)\n",
    "\n",
    "titanic_tree_pruned_cv.fit(X_train,Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(titanic_tree_pruned_cv.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = titanic_tree_pruned_cv.cv_results_['mean_test_score']\n",
    "stds = titanic_tree_pruned_cv.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, titanic_tree_pruned_cv.cv_results_['params']):\n",
    "    print(\"Accuracy = %0.3f (+/%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.errorbar(range(1,16,1), [m for m in means], yerr=stds, fmt='--o')\n",
    "plt.title('Accuracy for different Depths', fontsize=20)\n",
    "plt.xlabel(\"Depth\", fontsize=16)\n",
    "plt.ylabel(\"Accuracy\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the plot, the optimal value for the depth of the decision tree is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate accuracy for test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_tree_pruned = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "tree=titanic_tree_pruned.fit(X_train, Y_train)\n",
    "predictions = titanic_tree_pruned.predict(X_test)\n",
    "print(\"Accuracy = {0:.4f}\".format(accuracy_score(Y_test, predictions)))\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "prob_pred = tree.predict_proba(X_test)[:, 1]\n",
    "thresholds = np.arange(0.0, 1.0, step=0.1)\n",
    "recall_scores = [metrics.recall_score(Y_test, prob_pred > t) for t in thresholds]\n",
    "precis_scores = [metrics.precision_score(Y_test, prob_pred > t) for t in thresholds]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have increase the accuracy with a smaller tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we represent the different values for the metrics obtained using different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thresholds, recall_scores, label=\"Recall @ t\")\n",
    "ax.plot(thresholds, precis_scores, label=\"Precision @ t\")\n",
    "ax.axvline(0.5, c=\"gray\", linestyle=\"--\", label=\"Default Threshold\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Metric @ Threshold\")\n",
    "ax.set_box_aspect(1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict_proba(X_test) > 0.3\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many nodes and leaves?\n",
    "print(\"Number of nodes: \", titanic_tree_pruned.tree_.node_count)\n",
    "print(\"Number of leaves: \", titanic_tree_pruned.get_n_leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can represent the set of rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "text_representation = tree.export_text(titanic_tree_pruned)\n",
    "print(text_representation)\n",
    "with open(\"decision_tree.log\", \"w\") as fout:\n",
    "    fout.write(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to deep down a bit more on the tree.<BR>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "# DOT data\n",
    "dot_data = tree.export_graphviz(titanic_tree_pruned, out_file=None, \n",
    "                                class_names=[\"No\",\"Yes\"],\n",
    "                                feature_names=X_train.columns,  \n",
    "                                filled=True)\n",
    "\n",
    "# Draw graph\n",
    "graph = graphviz.Source(dot_data, format=\"png\") \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it into a high resolution image\n",
    "graph.render(\"titanic_tree_graphivz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative visualization: dtreeviz\n",
    "we need to install the powerful library *dtreeviz* for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ! pip install dtreeviz\n",
    "import dtreeviz\n",
    "\n",
    "viz_cmodel = dtreeviz.model(titanic_tree_pruned,\n",
    "                           X_train=X_train,\n",
    "                           y_train=Y_train,\n",
    "                           feature_names=X_train.columns,\n",
    "                           target_name='survived')\n",
    "viz_cmodel.view(scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display now frequencies for each node.<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_cmodel.leaf_sizes(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see node id=6 is the one with maximum amount of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare it with target classes\n",
    "viz_cmodel.ctree_leaf_distributions(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore that node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_cmodel.node_stats(node_id=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And highlight it in the tree so that we can take a closer look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train[X_train.columns].iloc[1]\n",
    "viz_cmodel.view(x=x, scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's going to analyze model performance (on test data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, predictions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "label_names = ['TN','FN','FP','TP']\n",
    "label_counts = ['{0:0.0f}'.format(value) for value in conf_mat.flatten()]\n",
    "labels = [f'{v1}\\n{v2}' for v1, v2 in zip(label_names,label_counts)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "# Draw heatmap using confusion matrix\n",
    "sns.heatmap(conf_mat, annot=labels, fmt='')\n",
    "ax.set_title('Confusion matrix')\n",
    "ax.set_xlabel('Actual Values')\n",
    "ax.set_ylabel('Predicted Values')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
